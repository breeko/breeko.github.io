<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on ML-Everything</title>
    <link>https://breeko.github.io/blog/</link>
    <description>Recent content in Blogs on ML-Everything</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://breeko.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Demo Apps and Building a Business off GPT-3</title>
      <link>https://breeko.github.io/blog/2020-09-03-demo-apps-and-building-a-business-off-gpt3/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2020-09-03-demo-apps-and-building-a-business-off-gpt3/</guid>
      <description>Demo Apps and Building a Business off GPT-3 Here’s a cool app. Give a description of a website and have one built for you using GPT-3 magic. Here’s an example:
A website like apple.com for twitter  But with demos like this, you have to read below the fold:
Copy is being generous, since its only one line. So GPT-3 is producing the essentially: “Twitter. We believe that everyone deserves the right to express themselves” and maybe the tab text.</description>
    </item>
    
    <item>
      <title>Using GPT-3 to Explain Jokes</title>
      <link>https://breeko.github.io/blog/2020-09-02-using-gpt3-to-explain-jokes/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2020-09-02-using-gpt3-to-explain-jokes/</guid>
      <description>Using GPT-3 to Explain Jokes There’s a Reddit bot that explains jokes. Well, that’s not exactly true, because its too good to be a bot and is curiously selective. Often times, the explanation is funnier than the joke. It hasn’t been active in about a year, but here’s an example:
 My wife and I went on our honeymoon to Australia. Unfortunately, I had to dial the help line.
  &amp;ldquo;G&amp;rsquo;day this is Tim, you&amp;rsquo;ve reached the Aussie help line.</description>
    </item>
    
    <item>
      <title>Optimal Bet Size Using Kelly Criterion</title>
      <link>https://breeko.github.io/blog/2020-03-09-optimal-bet-size-using-kelly-criterion/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2020-03-09-optimal-bet-size-using-kelly-criterion/</guid>
      <description>Optimal Bet Size Using Kelly Criterion TLDR: When placing a wager, choosing a bet size is as important as an edge. Kelly Criterion is a simple formula that determines the bet size for the highest growth in repeated games. I made a calculator/simulator to play out alternative strategies.
Suppose I offered you to play a game where we flip coins using a fair coin. If it lands on tails, you lose $1, but if it lands on heads, you win $1.</description>
    </item>
    
    <item>
      <title>Buying a Home in the US is Increasingly Attainable</title>
      <link>https://breeko.github.io/blog/2020-02-28-buying-a-home-is-increasingly-affordable/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2020-02-28-buying-a-home-is-increasingly-affordable/</guid>
      <description>Buying a Home in the US is Increasingly Attainable There’s a common belief that the American dream is dead. One of the causes is home affordability. But buying a home is actually incredibly affordable now relative to the last 50 years when you consider mortgage rates and median income.
All charts below have been made by Chart It, a free tool I created for creating and sharing charts.
History of 30 Year Fixed Rate Mortgages Today the most popular mortgage loan in the US is the 30 year mortgage, but this wasn’t always the case.</description>
    </item>
    
    <item>
      <title>How Renaissance Technologies Solved the Market: Part 3 - Incentives</title>
      <link>https://breeko.github.io/blog/2019-11-28-how-renaissance-technologies-solved-the-market-part-3/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-11-28-how-renaissance-technologies-solved-the-market-part-3/</guid>
      <description>How Renaissance Technologies Solved the Market: Part 3 — Incentives Renaissance Technologies is the most successful hedge fund in history, netting investors an average of 39% a year after fees over the last 3 decades. Renaissance stands out among its peers as by far the best performing fund.
 One reason is that the incentives Renaissance decided to focus on are different than that of other funds.
This is part 3 of my thoughts on Renaissance Technologies after reading The Man Who Solved the Market.</description>
    </item>
    
    <item>
      <title>How Renaissance Technologies Solved the Market: Part 2 - Hiring Academics</title>
      <link>https://breeko.github.io/blog/2019-11-20-how-renaissance-technologies-solved-the-market-part-2/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-11-20-how-renaissance-technologies-solved-the-market-part-2/</guid>
      <description>Renaissance Technologies is the most successful hedge fund in history, averaging nearly 40% annual net returns over the last 30 years. The book The Man Who Solved the Market discusses the fund and its founder Jim Simons in depth.
This is part 2 on a series discussing the book. Part 1 discussed the Renaissance’s data pipeline. This part will discuss Renaissance’s unusual practice of hiring almost exclusively from academia.
Academia Simons was a successful mathematician prior to starting Renaissance at the age of 40.</description>
    </item>
    
    <item>
      <title>How Renaissance Technologies Solved the Market: Part 1 - Pipeline</title>
      <link>https://breeko.github.io/blog/2019-11-19-how-renaissance-technologies-solved-the-market-part-1/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-11-19-how-renaissance-technologies-solved-the-market-part-1/</guid>
      <description>The new book The Man Who Solved the Market details Jim Simons and his hedge fund Renaissance Technologies in great detail. Jim Simons is a world renowned mathematician that left academia and started a hedge fund at the age of 40. He went on to become the most successful hedge fund manager and one of the richest people in the world.
The crown jewel of Renaissance Technologies is the Medallion Fund.</description>
    </item>
    
    <item>
      <title>Word Crossword Search in Typescript and React Part 1</title>
      <link>https://breeko.github.io/blog/2019-11-02-word-crossword-search-in-typescript-and-react-part-1/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-11-02-word-crossword-search-in-typescript-and-react-part-1/</guid>
      <description>I don&amp;rsquo;t normally play mobile games, but I do take the train every day so I&amp;rsquo;m somewhat aware of the mobile game landscape. One game that seems popular is basically a word jumble in the form of a crossword puzzle. One example of such a game is Word Crossword Search. You get a series of letters and try to make to make as many words as you can. The crossword format gives you hints.</description>
    </item>
    
    <item>
      <title>How Facial Recognition Works Part 4, Comparing Congressmen to Mugshots</title>
      <link>https://breeko.github.io/blog/2019-09-30-how-facial-recognition-works-part-4/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-09-30-how-facial-recognition-works-part-4/</guid>
      <description>This is part 4 of my series on facial recognition. Part 1 was about face detection, part 2 was about facial landmarks and part 3 was about accuracy over time.
This post I will compare US congressmen to a public dataset of mugshots. This was inspired by the ACLU claim that Amazon’s face recognition falsely matched 28 members of Congress with mugshots.
The ACLU post didn&amp;rsquo;t include any source code or source of the mugshot datasets or the congressman dataset.</description>
    </item>
    
    <item>
      <title>How Facial Recognition Works Part 3, How a Face Changes Over 10 Years</title>
      <link>https://breeko.github.io/blog/2019-09-23-how-facial-recognition-works-part-3/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-09-23-how-facial-recognition-works-part-3/</guid>
      <description>This is part 3 of a series of posts about facial recognition. In part 1 I discussed facial detection and part 2 I discussed facial landmarks. In this post, I&amp;rsquo;ll go into how accurate some off the shelf facial recognition are and how well they work as a subject ages.
I found this video of a man (boy?) that took a picture of himself every day over 10 years starting at age 12.</description>
    </item>
    
    <item>
      <title>How Facial Recognition Works Part 2, Facial Landmarks</title>
      <link>https://breeko.github.io/blog/2019-07-16-how-facial-recognition-works-part-2/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-07-16-how-facial-recognition-works-part-2/</guid>
      <description>In my last post I discussed how face detection works. In this post I&amp;rsquo;ll discuss how landmark detection works.
Python offers some great free libraries for face recognition. Sorry, thats a lie. They offer great wrappers for C++ libraries like dlib. Using face_recognition, we can identify the face locations of an image is as simple as face_recognition.face_locations.
When talking about what distinguishes one face from another we normally talk about facial landmarks.</description>
    </item>
    
    <item>
      <title>Scala’s Case Class in Python with Case Matching</title>
      <link>https://breeko.github.io/blog/2019-08-19-python-case-classes/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-08-19-python-case-classes/</guid>
      <description>I’ve been doing a lot of Scala programming lately. Scala is a statically typed language that compiles to the JVM. Scala doesn’t break away from object oriented programming but has a lot of functional programming features.
One of my favorite features of Scala is its case classes. Case classes are a lot like regular classes but they’re easier to setup and usually used to model immutable data. They also allow for easy pattern matching.</description>
    </item>
    
    <item>
      <title>Facebook Derangement Syndrom and Libra</title>
      <link>https://breeko.github.io/blog/2019-07-12-facebook-derangement-syndrom-and-libra/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-07-12-facebook-derangement-syndrom-and-libra/</guid>
      <description>Have you heard? Facebook is coming out with a new cryptocurrency that&amp;rsquo;s going to usher in a dystopian corporate nightmare and usurp governments around the world?
  LOLOLOLOL   The Facebook Libra project was announced a few weeks ago but it’s already causing waves in some circles. Below are some objections.
Libra will take money and sell IOUs for some future money. Yes, this also happens when Amazon (or any business) sells you a gift card.</description>
    </item>
    
    <item>
      <title>How Facial Recognition Works Part 1: Face Detection</title>
      <link>https://breeko.github.io/blog/2019-07-08-how-facial-recognition-works/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-07-08-how-facial-recognition-works/</guid>
      <description>Much has been written about facial recognition and its role in society. As with a lot of topics concerning artificial intelligence, it is often discussed with an air of mysticism, as though all the all seeing machines can now peer into our souls. Depending on the narrative of the piece, its accuracy is chillingly accurate or appallingly inadequate for use. Amazon got flack for pitching their Reckognition service to law enforcement, San Fransisco banned the technology, and it has even been called racist.</description>
    </item>
    
    <item>
      <title>Calculating the Probability of Skittle Distribution by Brute Force</title>
      <link>https://breeko.github.io/blog/2019-04-18-calculating-the-probability-of-skittle-distribution-by-brute-force/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-04-18-calculating-the-probability-of-skittle-distribution-by-brute-force/</guid>
      <description>A recent blog post caught my attention. The author wanted to see how long it would take for him to get an identical distribution of Skittles in a bag. He estimated a reasonable estimate of 400–500 bags would be required for him to open before he found a matching bag. After [spoiler alert] 468 bags, he finally found a matching bag.
I wanted to test this his results empirically while also being lazy.</description>
    </item>
    
    <item>
      <title>Building an Object Detection API with AWS S3, Rekognition and Lambda</title>
      <link>https://breeko.github.io/blog/2019-03-18-building-an-object-detection-api-with-aws-s3-rekognition-and-lambda/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2019-03-18-building-an-object-detection-api-with-aws-s3-rekognition-and-lambda/</guid>
      <description>In a prior post, Offline Object Detection and Tracking on a Raspberry Pi, I wrote an implementation of an offline object detection model. Since that time, aws has begun to offer some great services in that space, so I felt it was time to write about building an online object detection model with aws.
Use-Case My use-case is the same as the original article: take a picture periodically, process it, and display some information as to the location of given objects over time.</description>
    </item>
    
    <item>
      <title>Predicting the Stock Market, p-Hacking and Why You Should Be Bullish</title>
      <link>https://breeko.github.io/blog/2018-11-29-predicting-the-stock-market-p-hacking-and-why-you-should-be-bullish/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-11-29-predicting-the-stock-market-p-hacking-and-why-you-should-be-bullish/</guid>
      <description>Stock prices are just a series of numbers. Let’s try to fit a model to those numbers. What could go wrong?
With the rise of stock market volatility in the last few months, there has been a renewed interest in the stock market. The stock market is a compelling challenge to engineers. It’s a mature market with practically unlimited depth and exceptionally low transaction costs. If you can digest the numbers and eek out a model that is just slightly better than random, you would have investors lining up to give you their money.</description>
    </item>
    
    <item>
      <title>Using ESPN Forecasts to Make Draft King Final Fantasy Football Picks</title>
      <link>https://breeko.github.io/blog/2018-11-06-using-espn-forecasts-to-make-draft-king-final-fantasy-football-picks/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-11-06-using-espn-forecasts-to-make-draft-king-final-fantasy-football-picks/</guid>
      <description>ESPN fantasy football projection are free and available historically. Although they differ from DraftKing, they are granular enough to be converted and compared. Let’s see their predictive power
In this post we’ll use ESPN predictions to optimize our fantasy pool. You can skip to the bottom for the code or just visit my github. For more information on R programming for data science, I recommend the book Practical Statistics for Data Scientists</description>
    </item>
    
    <item>
      <title>Generating Letters Using Generative Adversarial Networks (GANs)</title>
      <link>https://breeko.github.io/blog/2018-11-05-generating-letters-using-generative-adversarial-networks-gans/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-11-05-generating-letters-using-generative-adversarial-networks-gans/</guid>
      <description>A generative adversarial network is a set of competing models that simultaneously learn to generate and discriminate real images from fake
In my last post post I wrote about variational auto encoders (VAEs). A VAE is composed of an encoder and decoder and can be used to compress and generate data.
In this post I’ll discuss Generative Adversarial Networks (GANs). Like VAEs, GANs are made up of two models: a generator and a discriminator and can also be used to generate data.</description>
    </item>
    
    <item>
      <title>Another &#39;Variational Auto Encoders Explained&#39; Post and Character Encoding</title>
      <link>https://breeko.github.io/blog/2018-10-25_another-variational-auto-encoders-explained-post-and-character-encoding/</link>
      <pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-10-25_another-variational-auto-encoders-explained-post-and-character-encoding/</guid>
      <description>Variational Auto Encoders are simpler than they appear and are the building blocks of generative models
Variational Auto Encoders are used to learn probability distribution function of images. By viewing their latent space we can see what’s really going on and use it to generate our own examples
I have read a fair number of posts about variational auto encoders but only recently did I try my hand in generating my own.</description>
    </item>
    
    <item>
      <title>Using Linear Regression to Make Fantasy Football Picks</title>
      <link>https://breeko.github.io/blog/2018-10-11_using-linear-regression-to-make-fantasy-football-picks/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-10-11_using-linear-regression-to-make-fantasy-football-picks/</guid>
      <description>Optimize your fantasy football picks with a linear regression in just a few lines of code.
Using a regression to predict fantasy football performance is easier than you think in R. With a few lines of code, you can predict player performance and optimize your lineup.
In a prior post, I wrote about using linear programming to optimize your fantasy football picks. Linear programming ensures you pick the best lineup based on some points projections and constraints (e.</description>
    </item>
    
    <item>
      <title>AI, Optimists vs Pessimists and Why The Singularity Isn’t Near</title>
      <link>https://breeko.github.io/blog/2018-10-08_ai-optimists-vs-pessimists-and-why-the-singularity-isn-t-near/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-10-08_ai-optimists-vs-pessimists-and-why-the-singularity-isn-t-near/</guid>
      <description>AI has its pessimists and optimists. The one thing they agree on is that the singularity is just around the corner. It’s not.
AI optimists and pessimists both agree that the singularity is just around the corner. Both think it will transform society. But practitioners think not much of anything will happen.
Last year I read Ray Kurzweil’s book How to Create a Mind and it made quite an impression on me.</description>
    </item>
    
    <item>
      <title>Using Python and Linear Programming to Optimize Fantasy Football Picks</title>
      <link>https://breeko.github.io/blog/2018-09-17_using-python-and-linear-programming-to-optimize-fantasy-football-picks/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-09-17_using-python-and-linear-programming-to-optimize-fantasy-football-picks/</guid>
      <description>Automated optimal fantasy football selection using linear programming
Historical fantasy football information is easily accessible and easy to digest. Use historical points or adjust as you see fit. With python and linear programming we can design the optimal line-up.
I’m not a big sports fan but I always liked the numbers. That’s why I was interested in Fantasy Football. It struck me as a relatively simple optimization problem. And with the rise of DraftKings and FanDuel, I figured there would be a lot of historical information available.</description>
    </item>
    
    <item>
      <title>Ranking Reddit Bots, Lambda Database Architecture and a File Systems as a Database</title>
      <link>https://breeko.github.io/blog/2018-09-09_ranking-reddit-bots-lambda-database-architecture-and-a-file-systems-as-a-database/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-09-09_ranking-reddit-bots-lambda-database-architecture-and-a-file-systems-as-a-database/</guid>
      <description>Botrank tracks votes for reddit bots. Updating records can be surprisingly tricky. Lambda Architecture can help.
Lambda Architecture is a novel way to manage a database. Data is immutable and everything is built from the ground up. Everything can be re-created and nothing is lost.
In my last post I wrote about a few Reddit bots I am working on. One of them, B0tRank, keeps track of “good bot” and “bad bot” comments and updates a ledger that has a rating of bots based on these votes.</description>
    </item>
    
    <item>
      <title>Reddit Bots, Drinking from the Fire Hose and Image Colorization</title>
      <link>https://breeko.github.io/blog/2018-09-07_reddit-bots-drinking-from-the-fire-hose-and-image-colorization/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-09-07_reddit-bots-drinking-from-the-fire-hose-and-image-colorization/</guid>
      <description>My latest obsession has been writing bots for Reddit. Reddit is an online forum that hosts a range of topics, everything from news and…
My latest obsession has been writing bots for Reddit. Reddit is an online forum that hosts a range of topics, everything from news and politics to strange, possibly nsfw captions to WikiHow images. But mostly, it’s just memes.
What’s nice about Reddit is the sheer volume of content.</description>
    </item>
    
    <item>
      <title>Lisp, Floating Points and Muller&#39;s Recurrence</title>
      <link>https://breeko.github.io/blog/2018-07-30_lisp-floating-points-and-muller-s-recurrence/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-07-30_lisp-floating-points-and-muller-s-recurrence/</guid>
      <description>Floating point number representations are annoying to work with. Lisp and by extension Clojure deal with them by using fractions instead.
Floating point representations can lead to some strange results. Lisp and Clojure have fraction representations built in, helping avoid many of the problems with floats.
I came across this article about why the IRS has had trouble to break away from Cobol. The article argues that a big reason is due to Cobol’s native support of fixed point as opposed to floating point.</description>
    </item>
    
    <item>
      <title>OpenCalc - React Native - Deep Dive (Part 2)</title>
      <link>https://breeko.github.io/blog/2018-07-23_opencalc-react-native-deep-dive-part-2/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-07-23_opencalc-react-native-deep-dive-part-2/</guid>
      <description>This is part 2 of a 2 part series on OpenCalc, an open-source mobile calculator built with react-native, javascript and flow. The first part dealt with the design and UI components and a previous post addressed writing the app the app market in general. The second part will deal with the calculation and validation. OpenCalc is available on iOS and Android.
  OpenCalc in action   The main controller has a property called brain, which is an instance of CalculatorBrain.</description>
    </item>
    
    <item>
      <title>OpenCalc - React Native - Deep Dive (Part 1)</title>
      <link>https://breeko.github.io/blog/2018-07-05_opencalc-react-native-deep-dive-part-1/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-07-05_opencalc-react-native-deep-dive-part-1/</guid>
      <description>OpenCalc is a mobile calculator written in React Native. Below is a deep dive on the inner workings and design decisions I made on OpenCalc
OpenCalc is a mobile calculator written in React Native. This is my first app using React Native and JavaScript. Below is a deep dive on the inner workings and design decisions I made on OpenCalc…
OpenCalc is a mobile calculator written in React Native. This is my first app using React Native and JavaScript.</description>
    </item>
    
    <item>
      <title>A Free Open-Source iPad Calculator and Why Your App Won&#39;t Make You Any Money</title>
      <link>https://breeko.github.io/blog/2018-06-28_a-free-open-source-ipad-calculator-and-why-your-app-won-t-make-you-any-money/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-06-28_a-free-open-source-ipad-calculator-and-why-your-app-won-t-make-you-any-money/</guid>
      <description>After an unsatisfactory selection of free (free to download, no ads/tracking or in app purchases) iPad calculator apps, I wrote one myself.
The app store won&amp;rsquo;t make you any money. So why do people keep trying to monetize even the most basic apps? I decided to write simple free open-source apps for everyone, starting with a calculator.
After an unsatisfactory selection of free (free to download, no ads/tracking or in app purchases) iPad calculator apps, I wrote and open sourced my own using React Native.</description>
    </item>
    
    <item>
      <title>Offline Object Detection and Tracking on a Raspberry Pi</title>
      <link>https://breeko.github.io/blog/2018-05-09_offline-object-detection-and-tracking-on-a-raspberry-pi/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-05-09_offline-object-detection-and-tracking-on-a-raspberry-pi/</guid>
      <description>Load and run YOLO (You Only Look Once) object detection model on a Raspberry Pi and track objects throughout the day.
In my last post I wrote about the YOLO model used for object detection. The most surprising thing was how simple the model is. It’s so simple that it can run offline on a raspberry pi
In my last post I wrote about the YOLO (You Only Look Once) model used for object detection.</description>
    </item>
    
    <item>
      <title>How to (actually) easily detect objects with deep learning on raspberry pi</title>
      <link>https://breeko.github.io/blog/2018-04-05_how-to-actually-easily-detect-objects-with-deep-learning-on-raspberry-pi/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-04-05_how-to-actually-easily-detect-objects-with-deep-learning-on-raspberry-pi/</guid>
      <description>YOLO provides state of the art real-time object detection and classification.
The YOLO image detection model is one of the fastest and most accurate object detection models. Flexible and fast, YOLO is a huge step forward in machine learning.
I came across a popular post on hackernews titled How to easily Detect Objects with Deep Learning on Raspberry Pi. The article discusses the YOLO object detection model that can be used for real-time object detection and classification.</description>
    </item>
    
    <item>
      <title>Everything you’ve ever wanted to know about New York City’s restaurant ratings</title>
      <link>https://breeko.github.io/blog/2018-03-25_everything-you-ve-ever-wanted-to-know-about-new-york-city-s-restaurant-ratings/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-03-25_everything-you-ve-ever-wanted-to-know-about-new-york-city-s-restaurant-ratings/</guid>
      <description>What do the food ratings tell us about restaurants and health departments?
Every restaurant in NYC receives a letter grade by the city. Using this information we can draw insights into safety and where to eat.
Anyone who’s been to New York City likely noticed the restaurant letter grades on virtually all eating establishments. The letter grades were introduced in 2010 and range from A through C, with A being the highest (best) rating.</description>
    </item>
    
    <item>
      <title>Nassim Taleb, Loaded Questions and Statistics for Hackers</title>
      <link>https://breeko.github.io/blog/2018-03-12_nassim-taleb-loaded-questions-and-statistics-for-hackers/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-03-12_nassim-taleb-loaded-questions-and-statistics-for-hackers/</guid>
      <description>Nassim Taleb baits financial professionals and students into an elementary mistake in probability. However a simple check could have helped.
Probability and statistics is hard and not always intuitive. But with modern computing, we can run simulations to get the answers, or at least tell us when we’re way off. Here I describe such methods.
In anticipation of reading Nassim Taleb’s new book Skin in the Game, I came across a paper Taleb wrote titled “We Don’t Quite Know What We Are Talking About When We Talk About Volatility”.</description>
    </item>
    
    <item>
      <title>Nassim Taleb, Absorbing Barriers and House Money</title>
      <link>https://breeko.github.io/blog/2018-03-07_nassim-taleb-absorbing-barriers-and-house-money/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-03-07_nassim-taleb-absorbing-barriers-and-house-money/</guid>
      <description>A recent EconTalk podcast featured Nassim Taleb in which he spoke about his new book Skin in the Game. During the discussion, he criticized…
A recent EconTalk podcast featured Nassim Taleb in which he spoke about his new book Skin in the Game. During the discussion, he criticized behavioral economists and social scientists for designing “one-shot” type experiments and trying to draw real life insights from the results. When in actuality, the more reasonable scenario is a series of interactions.</description>
    </item>
    
    <item>
      <title>Reinforcement learning with sparse rewards</title>
      <link>https://breeko.github.io/blog/2018-02-26_reinforcement-learning-with-sparse-rewards/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-02-26_reinforcement-learning-with-sparse-rewards/</guid>
      <description>This is a continuation of a series of posts on reinforcement learning. This will continue the discussion from the last post and use the…
This is a continuation of a series of posts on reinforcement learning. This will continue the discussion from the last post) and use the OpenAI environment discussed in an earlier post.
Reinforcement learning shouldn’t be hard. The idea is simple enough:
 Try some things randomly and save down the states and the rewards Train a network to predict the reward Use the network to choose the highest reward, allowing for some randomness Continue to train based on those experiences  You’ll read tutorials that get everything to work swimmingly.</description>
    </item>
    
    <item>
      <title>Learning from pixels and Deep Q-Networks with Keras</title>
      <link>https://breeko.github.io/blog/2018-02-20_learning-from-pixels-and-deep-q-networks-with-keras/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-02-20_learning-from-pixels-and-deep-q-networks-with-keras/</guid>
      <description>This is a continuation of my series on reinforcement learning. I’d recommend the second post if you’re unfamiliar with OpenAI and the third…
This is a continuation of my series on reinforcement learning. I’d recommend the second post if you’re unfamiliar with OpenAI and the third post if you’re unfamiliar with using neural networks to train a policy. This borrows some code and ideas from Arthur Juliani’s post, especially the game environment.</description>
    </item>
    
    <item>
      <title>Policy Based Reinforcement Learning with Keras</title>
      <link>https://breeko.github.io/blog/2018-02-12_policy-based-reinforcement-learning-with-keras/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-02-12_policy-based-reinforcement-learning-with-keras/</guid>
      <description>This post will discuss reinforcement learning through policy based agents on an OpenAI environment
Policy based reinforcement learning is simply training a neural network to remember the actions that worked best in the past. This framework provides incredible flexibility and works across many envs
This post will discuss reinforcement learning through policy based agents. We’ll be using OpenAI’s gym environment which I discussed on my last post. The next few posts are heavily influenced by Arthur Juliani’s great series on reinforcement learning.</description>
    </item>
    
    <item>
      <title>Evolutionary Learning Models with OpenAI</title>
      <link>https://breeko.github.io/blog/2018-02-05_evolutionary-learning-models-with-openai/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-02-05_evolutionary-learning-models-with-openai/</guid>
      <description>Evolutionary learning models are a great introduction to machine learning because they’re simple to understand conceptually and…
Evolutionary learning models are a great introduction to machine learning because they’re simple to understand conceptually and surprisingly easy to implement. In this post, I’ll create an evolutionary learning model to use on the OpenAI. The great thing about OpenAI is the simple API and large number of environments to experiment on. So any bot we create in one environment can (in theory) be used on any other environment.</description>
    </item>
    
    <item>
      <title>Tic-Tac-Toe and Connect-4 using Mini-Max</title>
      <link>https://breeko.github.io/blog/2018-01-29_tic-tac-toe-and-connect-4-using-mini-max/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://breeko.github.io/blog/2018-01-29_tic-tac-toe-and-connect-4-using-mini-max/</guid>
      <description>A lot of ink has been spilled about machine learning techniques being used to beat people in games. From Deep Blue (chess) in the 1990s, to…
A lot of ink has been spilled about machine learning techniques being used to beat people in games. From Deep Blue (chess) in the 1990s, to AlphaGo (Go) more recently, computers seem to be performing well against their human counterparts. Even games like poker aren’t completely safe from the machine takeover.</description>
    </item>
    
  </channel>
</rss>